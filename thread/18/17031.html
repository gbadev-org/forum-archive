<!doctype html>
<html>
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <title>faster normalizer - gbadev.org forum archive</title>
        <link rel="stylesheet" href="/forum-archive/static/pure-min.css" />
        <link rel="stylesheet" href="/forum-archive/static/main.css" />
    </head>
    <body>
        <h1>gbadev.org forum archive</h1>

        <i>This is a read-only mirror of the content originally found on forum.gbadev.org
        (now offline), salvaged from Wayback machine copies. </i><br />

        <h2>DS development > faster normalizer</h2>
<div id="posts">
<div class="post">
    <h4>#171888 - ritz - Thu Dec 31, 2009 3:37 pm</h4>
    <div class="postbody"><span class="postbody">Using the reciprocal instead of division is well known, but I thought I'd post my DS version of it for those who are interested. Compared to the libnds normalizef32(), the code below is more than 2x faster on the hardware:
<br/>
<br/>
</span><table align="center" border="0" cellpadding="3" cellspacing="1" width="90%"><tr> <td><span class="genmed"><b>Code:</b></span></td> </tr> <tr> <td class="code">STATIC_INL
<br/>
void v_fnormalizef32 (int32* a)
<br/>
{
<br/>
   int32 m;
<br/>
<br/>
   m = sqrtf32(dotf32(a,a));
<br/>
<br/>
   // get reciprocal, not using divf32()
<br/>
   // DIV_32_32 is half the clks: numerator = 1
<br/>
<br/>
   REG_DIVCNT = DIV_32_32;
<br/>
   while (REG_DIVCNT &amp; DIV_BUSY) ;
<br/>
   REG_DIV_NUMER_L = 4096 &lt;&lt; 12;
<br/>
   REG_DIV_DENOM_L = m;
<br/>
   while (REG_DIVCNT &amp; DIV_BUSY) ;
<br/>
<br/>
   m = REG_DIV_RESULT_L;
<br/>
<br/>
   // multiply reciprocal instead of 3 divides
<br/>
<br/>
   a[0] = mulf32(a[0],m);
<br/>
   a[1] = mulf32(a[1],m);
<br/>
   a[2] = mulf32(a[2],m);
<br/>
}</td> </tr></table><span class="postbody">
<br/>
I'm posting here instead of supplying a patch because there is a very tiny precision hit using this method.
<br/>
<br/>
I actually played around with that magic inverse sqrt hack but it was only a tad faster. The hardware sqrt on the DS is very, very good. Here's my (unused) inverse sqrt code for fun:
<br/>
<br/>
</span><table align="center" border="0" cellpadding="3" cellspacing="1" width="90%"><tr> <td><span class="genmed"><b>Code:</b></span></td> </tr> <tr> <td class="code">STATIC_INL
<br/>
int32 v_finvsqrtf32 (int32 f32x)
<br/>
{
<br/>
   union { float f; int32 i; } u;
<br/>
   u.f = f32tofloat(f32x);
<br/>
   u.i = 0x5f375a86 - (u.i &gt;&gt; 1);
<br/>
   int32 uff32 = floattof32(u.f);
<br/>
   return mulf32(uff32,(6144-mulf32((f32x&gt;&gt;1),mulf32(uff32,uff32))));
<br/>
}</td> </tr></table><span class="postbody">
<br/>
This would be a lot faster if I had the time/smarts to figure out using fixed instead of floats for this (there's actually code in Clutter that figured this out to some degree). Obviously, f32tofloat() is dragging. Even so, this code is really quite fast.
<br/>
<br/>
Anyway, happy new year to all :) Don't drink and drive!</span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#171891 - DiscoStew - Thu Dec 31, 2009 5:55 pm</h4>
    <div class="postbody"><span class="postbody">To add to this, because the hardware for math operations like sqrt and division work independently of the CPU, you can streamline calculations for normalizing by having those math operations work at the same time while doing other calculations with the CPU. But, for this to work, you have to have your list of vectors to be ready for normalizing prior to starting it.
<br/>
<br/>
I'll have to look through my backups for the actual code, but I've used the technique back when trying to reduce processing time for calculating normals on a model with smooth-skinning on the NDS.<br/>_________________<br/><span style="font-weight: bold">DS</span> - It's all about <span style="font-weight: bold">D</span>isco<span style="font-weight: bold">S</span>tew</span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#171895 - sajiimori - Thu Dec 31, 2009 9:27 pm</h4>
    <div class="postbody"><span class="postbody">You can be slightly more parallel by setting up most of the div while the sqrt is busy.
<br/>
<br/>
Due to the non-triviality of the code, I'd suggest uninlining it to reduce cache misses in the average case.  (A cache miss -- loading 8 ARM instructions -- takes longer than a divide.)  For the special case, where it's called in a loop, a separate inline version can be provided, e.g. v_fnormalizef32_inl.</span><span class="gensmall"></span></div>    
</div>
</div>

    </body>
</html>
