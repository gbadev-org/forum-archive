<!doctype html>
<html>
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <title>Console Font on Sub Screen Issue with 16 bit Background - gbadev.org forum archive</title>
        <link rel="stylesheet" href="static/pure-min.css" />
        <link rel="stylesheet" href="static/main.css" />
    </head>
    <body>
        <h1>gbadev.org forum archive</h1>

        This is a mirror of the content originally found on forum.gbadev.org
        (now offline), salvaged from Wayback machine copies. <br />

        <h2>DS development > Console Font on Sub Screen Issue with 16 bit Background</h2>
<div id="posts">
<div class="post">
    <h4>#148847 - jonezer4 - Fri Jan 11, 2008 4:16 am</h4>
    <div class="postbody"><span class="postbody">Hey all, I have a problem getting console font to work on my subscreen, displaying over a graphic background. It used to be a 256x256 8-bit background, and my code worked fine, but I have had to change it to a 16-bit (I couldn't get Grit to make 8bit backgrounds).
<br/>
<br/>
So anyway, my question is, how do I go about getting a console default font to work over the new 16 bit background? 
<br/>
<br/>
Here's my old code (the one that worked with 8 bit backgrounds):
<br/>
<br/>
</span><table align="center" border="0" cellpadding="3" cellspacing="1" width="90%"><tr> <td><span class="genmed"><b>Code:</b></span></td> </tr> <tr> <td class="code">
<br/>
void initializeVRAM()
<br/>
{
<br/>
   //Map VRAM
<br/>
     vramSetMainBanks(VRAM_A_MAIN_BG_0x06000000, VRAM_B_MAIN_SPRITE_0x06400000,
<br/>
                VRAM_C_SUB_BG_0x06200000, VRAM_D_SUB_SPRITE);
<br/>
<br/>
<br/>
   //Use main Screen (bottom) for image
<br/>
   videoSetMode(MODE_5_2D   | DISPLAY_BG3_ACTIVE
<br/>
                     | DISPLAY_SPR_ACTIVE      //Initiate sprites
<br/>
                     | DISPLAY_SPR_1D         //1D sprites, tile mode
<br/>
                     | DISPLAY_SPR_1D_SIZE_256   //Setting each index to 256 bytes. This 
<br/>
                     );                     //will allow for indexes of multiples 
<br/>
                                          //of 16, and hence 1024/16=64 sprites.
<br/>
                     
<br/>
   BG3_CR = BG_BMP8_256x256 | BG_BMP_BASE(0) | BG_PRIORITY(3);
<br/>
   
<br/>
<br/>
    // Use the sub screen (top) for output
<br/>
   videoSetModeSub(MODE_5_2D | DISPLAY_BG0_ACTIVE //text
<br/>
                       | DISPLAY_BG2_ACTIVE //image
<br/>
                       | DISPLAY_SPR_ACTIVE   //sprites!
<br/>
                       | DISPLAY_SPR_1D
<br/>
                       | DISPLAY_SPR_1D_SIZE_256
<br/>
                       );         
<br/>
            
<br/>
   //vramSetBankH(VRAM_H_SUB_BG);
<br/>
   //vramSetBankI(VRAM_I_SUB_SPRITE);
<br/>
<br/>
  ///////////////set up our bitmap background///////////////////////
<br/>
<br/>
   SUB_BG2_CR = BG_BMP8_256x256 | BG_BMP_RAM_SUB(1)  | BG_PRIORITY(3);
<br/>
   SUB_BG0_CR = BG_MAP_BASE(31) |  BG_PRIORITY(1)    | BG_COLOR_16 ;//use bg1 for the text
<br/>
   //SUB_BG2_CR = BG_BMP8_256x256 | BG_BMP_BASE(1)  | BG_PRIORITY(1);            
<br/>
   //these are rotation backgrounds so you must set the rotation attributes:
<br/>
    //these are fixed point numbers with the low 8 bits the fractional part
<br/>
    //this basicaly gives it a 1:1 translation in x and y so you get a nice flat bitmap
<br/>
        BG3_XDX = 1 &lt;&lt; 8;
<br/>
        BG3_XDY = 0;
<br/>
        BG3_YDX = 0;
<br/>
        BG3_YDY = 1 &lt;&lt; 8;
<br/>
        BG3_CX = 0 &lt;&lt; 8;
<br/>
        BG3_CY = 0 &lt;&lt; 8;
<br/>
      
<br/>
      SUB_BG2_XDX = 1 &lt;&lt; 8;
<br/>
        SUB_BG2_XDY = 0;
<br/>
        SUB_BG2_YDX = 0;
<br/>
        SUB_BG2_YDY = 1 &lt;&lt; 8;
<br/>
        SUB_BG2_CY = 32 &lt;&lt; 8; //preventing console font from writing over data
<br/>
<br/>
<br/>
   dmaCopy(mainBG_bin, BG_GFX, 256 * 192);            //These offsets are for console font
<br/>
   dmaCopy(mainBGPal_bin,BG_PALETTE, mainBGPal_bin_size);
<br/>
   
<br/>
   dmaCopy(mainBG_bin + 256*192, &amp;BG_GFX_SUB[0x1000], 256 * 256);
<br/>
   dmaCopy(mainBGPal_bin, &amp;BG_PALETTE_SUB[0x1000], mainBGPal_bin_size);   
<br/>
<br/>
   //consoleInit() is a lot more flexible but this gets you up and running quick
<br/>
   consoleInitDefault((u16*)SCREEN_BASE_BLOCK_SUB(31), (u16*)CHAR_BASE_BLOCK_SUB(0), 16);
<br/>
<br/>
   BG_PALETTE_SUB[255] = RGB15(31,31,5); //font color must be set here
<br/>
}
<br/>
<br/>
</td> </tr></table><span class="postbody"></span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#148879 - PypeBros - Fri Jan 11, 2008 5:26 pm</h4>
    <div class="postbody"><span class="postbody">I'd say you don't have much to do to switch from 8bit to 16bit BG and keep the console working, since it's on another plane ... well, as long as the 16-bit BG doesn't require so much VRAM that you suddenly overwrite the place where you stored your font and console map, of course.<br/>_________________<br/><a class="postlink" href="http://sylvainhb.blogspot.com/p/sprite-editor.html" target="_blank"> SEDS: Sprite Edition on DS</a> :: <a class="postlink" href="http://sylvainhb.blogspot.com/search/label/modplayer" target="_blank">modplayer</a></span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#148881 - eKid - Fri Jan 11, 2008 5:31 pm</h4>
    <div class="postbody"><span class="postbody">I don't think you can have a 16bit background and the console together because a 256x256 16bit background takes up a whole 128kb of memory..... And you only get 128kb for all sub-bg vram :)</span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#148882 - PypeBros - Fri Jan 11, 2008 5:39 pm</h4>
    <div class="postbody"><span class="postbody"></span><table align="center" border="0" cellpadding="3" cellspacing="1" width="90%"><tr> <td><span class="genmed"><b>eKid wrote:</b></span></td> </tr> <tr> <td class="quote">I don't think you can have a 16bit background and the console together because a 256x256 16bit background takes up a whole 128kb of memory..... And you only get 128kb for all sub-bg vram :)</td> </tr></table><span class="postbody">
<br/>
<br/>
That somehow confirm the difficulty to get it working, true.
<br/>
Still, the screen is 256x192, which would leave you with 32KB "unused" at the end of the C bank, which you could safely use to store tiles and map for the console, no ? 
<br/>
<br/>
Well, that'd work only if you have a still background, i admit.
<br/>
<br/>
(too bad, we can't map both banks C and one of the "alternate" banks H/I to get a few extra 16 KB of VRAM on sub_bg)<br/>_________________<br/><a class="postlink" href="http://sylvainhb.blogspot.com/p/sprite-editor.html" target="_blank"> SEDS: Sprite Edition on DS</a> :: <a class="postlink" href="http://sylvainhb.blogspot.com/search/label/modplayer" target="_blank">modplayer</a></span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#148888 - jonezer4 - Fri Jan 11, 2008 6:50 pm</h4>
    <div class="postbody"><span class="postbody">So after messing with this last night for a few hours, I guess the better question would be: "Is it possible to make 8-bit image files with Grit, and if so how?"
<br/>
<br/>
Thanks everyone for all your help.</span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#148890 - eKid - Fri Jan 11, 2008 7:02 pm</h4>
    <div class="postbody"><span class="postbody">from grit usage:
<br/>
-gB{n}         Gfx bit depth (1, 2, 4, 8, 16) [img bpp]
<br/>
<br/>
-gB8 in the command line should produce 8bit output, it defaults to the input image's bit depth.</span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#148896 - jonezer4 - Fri Jan 11, 2008 7:29 pm</h4>
    <div class="postbody"><span class="postbody"></span><table align="center" border="0" cellpadding="3" cellspacing="1" width="90%"><tr> <td><span class="genmed"><b>eKid wrote:</b></span></td> </tr> <tr> <td class="quote">from grit usage:
<br/>
-gB{n}         Gfx bit depth (1, 2, 4, 8, 16) [img bpp]
<br/>
<br/>
-gB8 in the command line should produce 8bit output, it defaults to the input image's bit depth.</td> </tr></table><span class="postbody">
<br/>
<br/>
I should have mentioned I've tried that, but it won't compile like that in ndslib. I guess I would need a way to tell ndslib to use grit with a 256 color palette, (specifying a palette in the grit file doesn't appear to work).</span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#148898 - eKid - Fri Jan 11, 2008 7:32 pm</h4>
    <div class="postbody"><span class="postbody">What does your grit file look like? You can put -gB8 in the grit file too...</span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#148904 - Cearn - Fri Jan 11, 2008 8:23 pm</h4>
    <div class="postbody"><span class="postbody"></span><table align="center" border="0" cellpadding="3" cellspacing="1" width="90%"><tr> <td><span class="genmed"><b>jonezer4 wrote:</b></span></td> </tr> <tr> <td class="quote"><table align="center" border="0" cellpadding="3" cellspacing="1" width="90%"><tr> <td><span class="genmed"><b>eKid wrote:</b></span></td> </tr> <tr> <td class="quote">from grit usage:
<br/>
-gB{n}         Gfx bit depth (1, 2, 4, 8, 16) [img bpp]
<br/>
<br/>
-gB8 in the command line should produce 8bit output, it defaults to the input image's bit depth.</td> </tr></table><span class="postbody">
<br/>
<br/>
I should have mentioned I've tried that, but it won't compile like that in ndslib. I guess I would need a way to tell ndslib to use grit with a 256 color palette, (specifying a palette in the grit file doesn't appear to work).</span></td> </tr></table><span class="postbody">
<br/>
I think you're confusing a number of things here. libnds is a code library with functions and macros useful for NDS programming. grit is a tool that takes a bitmap file, converts it to bitmap formats that can be used for GBA/NDS graphics and exports it as raw binary data or source-code arrays. It is the <span style="font-style: italic">makefile</span> that uses grit to convert the images and your code that uses its output, not libnds.
<br/>
<br/>
It's possible that the makefile doesn't use the right rules (or the wrong order) for grit, that the grit options aren't correct, or that you're not using grit's output correctly. Please specify which options you're using for grit, and what error you get when building the project. As the others have said, you need `-gB8' for 8bit output. You might also need `-gb' if you want bitmap output instead of tiles. If you need more examples of how you can work with grit, consider looking my <a class="postlink" href="http://www.coranac.com/2007/12/12/a-grit-demo-part-i/" target="_blank">grit demo</a>.
<br/>
<br/>
Also, the console system in libnds can only use tiled backgrounds in 4bit (16color) or 8bit (256color) modes, not 16bit color. The last parameter in consoleInitDefault() is actually the number of colors, not the bitdepth.</span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#148968 - jonezer4 - Sat Jan 12, 2008 8:01 pm</h4>
    <div class="postbody"><span class="postbody">Alright, I think I have it all figured out.
<br/>
<br/>
-gB16 will format your image as an untiled bitmap, but...
<br/>
<br/>
-gB8 will format your image as tiles
<br/>
<br/>
-gb8 will format your image as a bitmap.
<br/>
<br/>
I don't know if that's a bug or what, but apparently Grit doesn't care about the capitalization of the b for 16 bit files, but it will default to tiling if you capitalize it on 8 bit files. In Glut's defense, the specs all say to use "gb" or "gt".</span><span class="gensmall"></span></div>    
</div>
<div class="post">
    <h4>#148974 - Cearn - Sat Jan 12, 2008 11:21 pm</h4>
    <div class="postbody"><span class="postbody"></span><table align="center" border="0" cellpadding="3" cellspacing="1" width="90%"><tr> <td><span class="genmed"><b>jonezer4 wrote:</b></span></td> </tr> <tr> <td class="quote">Alright, I think I have it all figured out.
<br/>
<br/>
-gB16 will format your image as an untiled bitmap, but...
<br/>
<br/>
-gB8 will format your image as tiles
<br/>
<br/>
-gb8 will format your image as a bitmap.
<br/>
<br/>
I don't know if that's a bug or what, but apparently Grit doesn't care about the capitalization of the b for 16 bit files, but it will default to tiling if you capitalize it on 8 bit files. In Glut's defense, the specs all say to use "gb" or "gt".</td> </tr></table><span class="postbody">
<br/>
In principle, the type of image (bitmap or tiled) is determined by `-gb' and `-gt', and the output bitdepth by `-gB<span style="font-style: italic">number</span>'. these are completely separate items. If you omit either of them, grit will try to figure out what you meant. If you omit the image type, tiled graphics are assumed except for direct-color (16bit) images because that has no tiled variant. These assumptions make sense for GBA graphics -- and NDS as well, although to a lesser extent.
<br/>
<br/>
The reason `-gb8' worked is probably because the input image was 8bit as well. The 8 behind '-gb' is actually ignored.</span><span class="gensmall"></span></div>    
</div>
</div>

    </body>
</html>
